---
title: "Coverage regression"
output: html_document
date: "2022-12-02"
---

# Fitting the Coverage Regression Model

```{r}
library(rstudioapi)
library(haven)
library(dplyr)
library(ggplot2)
library(readr)
library(measurements)
library(geosphere)
```

```{r}
#running this should automatically configure the filepath
path <- paste0(dirname(getSourceEditorContext()$path), '/data/raw/')
setwd(path)

# load all relevant datasets
commtowers <- read_dta('commtowers.dta')
coverage <- read_dta('coverage.dta')

# Find relevant columns in commtowers
is_uhf <- as.integer(commtowers$channel > 13) # 0 is VHF, 1 is UHF
is_uhf

# We want Visual Power to be in increments of 100 kW.
# I think power_vis column is in kW, so divide by 100.
kw_100 <- commtowers$power_vis / 100

# We want height above ground to be measured in increments of 100 feet
# hgtground column is in feet, so divide by 100
hgt_100 <- commtowers$hgtground / 100

tower_df_unclean <- data.frame(is_uhf, kw_100, hgt_100, station=commtowers$station)
tower_df <- na.omit(tower_df_unclean)

#remove satellite stations from consideration
coverage <- coverage[coverage$satellite == 0,]

# Calculate distance from county centroid to channel's tower
covrate_linearized <- coverage$covrate
covrate_linearized[covrate_linearized=="5-24%"] <- 20
covrate_linearized[covrate_linearized=="25-50%"] <- 40
covrate_linearized[covrate_linearized=="over 50%"] <- 90
covrate_linearized[covrate_linearized=="."] <- NA

dists <- sapply(1:nrow(coverage), function(i) {
  # Get <station, county> pair
  stn <- coverage$station[i]
  county_lat <- coverage$lathh[i]
  county_long <- coverage$longhh[i]
  if (stn %in% commtowers$station) {
    # compute distance from that county's population centroid to the station's tower
    tower_info <- commtowers[commtowers$station==stn,]
    dist <- distm(c(county_long, county_lat), 
          c(tower_info$longtower, tower_info$lattower), fun = distHaversine)
    
    # Convert meters to miles
    dist_mi <- conv_unit(dist, "m", "mile")
    return(dist_mi)
  } 
  return(NA)
})

dists[dists>=200] <- NA
# Each row is a <county, station> pair, with its distance to the broadcasting tower
cov_df <- na.omit(data.frame(station=coverage$station, dists_10 = dists/10, 
                             covrate_linearized,
                             state=coverage$state_hh, county=coverage$county_hh, 
                             totalhh = coverage$totalhh))
# Join with info on the tower
cov_df <- inner_join(x=cov_df, y=tower_df, by = 'station')

#sum(is.na(cov_df)) # no na's

coverage.lm <- lm(covrate_linearized ~ dists_10 + is_uhf + kw_100 + hgt_100 
                  + dists_10*is_uhf, data=cov_df, weights=totalhh)

coef(coverage.lm)
```
## Extra: Fitting Different Coverage Regression Model

Something different and fun I want to try: what if we did a logistic regression,
and disaggregated the data so that each observation is a TV household in a county-station pairing,
and the response variable is now whether or not that TV household in that county can receive the station.
We have coverage rates for all TV households in each county-station pairing already, and the number of TV households in the county, so we can just multiply to get the number of TV households that get the station, and disaggregate so that
a proportion (the coverage rate) of TV households get '1' as the response and everyone else gets '0'.
Who gets '1' and who gets '0' doesn't matter, since there are no other household-level variables to worry
about (everyone in a county-station pairing has the same covariates).

```{r}
# extra: logistic regression model
households <- cov_df$totalhh
covrates <- as.integer(cov_df$covrate_linearized) / 100
viewers <- round(households*covrates)
not_viewers <- households - viewers
for (i in 1:nrow(cov_df)) {
  ctystation_viewers <- rep(1, viewers[i])
  ctystation_notviewers <- rep(0, not_viewers[i])
  ctystation_outcome <- c(ctystation_viewers, ctystation_notviewers)
}


```

```{r}
# maybe we can try this later, don't worry about this now
big_df <- cov_df[rep(row.names(cov_df), cov_df$totalhh),]
cov_df
```

# Using Coverage Regression Model to Predict Coverage Rate of SS Stations

```{r}
path <- paste0(dirname(getSourceEditorContext()$path), '/data/raw/')
setwd(path)

SSstations <- read_dta('SSstations.dta')
pbs_towers <- read_dta('pbstowers.dta')
counties <- read_dta('counties.dta')
```

```{r}

# match PBS towers with the stations that air Sesame Street
SStowers <- inner_join(pbs_towers, SSstations, by = 'station')
# get all possible station and county pairs 
crossprod <- full_join(SStowers, counties, by = character())
# grab the station and county coordinates
station_locs <- matrix(c(crossprod$longtower, crossprod$lattower), ncol = 2)
county_locs <- matrix(c(crossprod$longhh, crossprod$lathh), ncol = 2)
# compute distances
dist <- distHaversine(p1=station_locs, p2=county_locs)
dist_mi <- conv_unit(dist, "m", "mile")
# add back to the crossproduct, and filter for <= 200 mi
crossprod <- crossprod %>% mutate(dist_mi = dist_mi)
SSstation_cty_pairs <- crossprod %>% filter(dist_mi <= 200)
# add the UHF indicator
SSstation_cty_pairs <- SSstation_cty_pairs %>% mutate(is_uhf = as.integer(SSstation_cty_pairs$channel.x > 13))
# grab columns that are of interest to the predictions
SSstation_cty_pairs <- SSstation_cty_pairs %>% select(power_vis, hgtground, dist_mi, is_uhf, ctyname, stname, ctyfips_hh, stfips_hh, pop70)
# drop any observations for which there is a missing value of any of these crucial measures for coverage prediction
SSstation_cty_pairs <- na.omit(SSstation_cty_pairs)
# note: there are no county-station pairings left with missing values in these columns

# do unit conversions before feeding into fitted regression
SSstation_cty_pairs <- SSstation_cty_pairs %>% mutate(dists_10 = dist_mi/10, kw_100 = power_vis/100, hgt_100 = hgtground/100)

# get coverage predictions
SScov_preds <- predict.lm(coverage.lm, SSstation_cty_pairs)
SSstation_cty_covs <- SSstation_cty_pairs %>% mutate(pred_coverage = SScov_preds)

# take maximum coverage for each county
SSstation_cty_final <- SSstation_cty_covs %>% group_by(ctyfips_hh, stfips_hh) %>% mutate(max_pred_cov = max(pred_coverage)) %>% filter(pred_coverage == max_pred_cov) %>% ungroup() %>% select(-pred_coverage)
```

```{r}
# displaying the final data frame
SSstation_cty_final
```
```{r}
# checking that the national coverage rate is roughly what we would expect, they got 65%
sum(SSstation_cty_final$pop70*(SSstation_cty_final$max_pred_cov/100))/sum(SSstation_cty_final$pop70)
# checks out!
```

A few notes about this process:

+ It seems like there's a few stations where the channel in `pbs_towers`
is different from the channel in `SSstations` (KTEH, KUON, WKSO). However, in all cases,
the mismatched channels would both either be classified as UHF or VHF, so there are 
no ambiguous cases.

+ Some of the counties have negative Sesame Street coverage, but it doesn't seem like the authors address this. Maybe a better reason to use a logistic regression instead, since in using a normal linear regression, you are not guaranteed to get coverages between 0 and 100 percent.